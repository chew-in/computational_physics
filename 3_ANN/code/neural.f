      PROGRAM PERCEPTRON 

C *** OI IS TRAINING INPUT DATASET, TJ IS TRAINING OUTPUTS
C *** OJ IS OUTPUT 
C *** W ARE THE WEIGHTS 
C *** DELTA IS PRODUCT OF OJ-TJ AND THE SLOPE OF TRANSFER FUNCTION

      REAL OI(4,3),TJ(4,1),OJ(4,1),W(3,1),DELTA(4,1)
      
      OPEN(UNIT=1,FILE='neural.out',STATUS='UNKNOWN')

C *** THIS IS BATCH TRAINING (ALL TRAINING INPUTS INTO ONE MATRIX)
      DATA OI(1,:)/0,0,1/
      DATA OI(2,:)/1,1,1/
      DATA OI(3,:)/1,0,1/
      DATA OI(4,:)/0,1,1/

C *** TRAINING OUTPUTS
      DATA TJ(:,1)/0,1,1,0/

C *** INITIALIZE WEIGHTS AT RANDOM BETWEEN -1 AND 1
      DO 7 J=1,3
      W(J,1)=2.*RAND()-1. 
    7 CONTINUE
      
C *** CHOOSE A LEARNING RATE
      ALPHA=1.

c *** CPU TIME
      CALL CPU_TIME(START)

C *** TRAIN OVER THESE MANY EPOCHS

      DO J=1,100000

C *** FORWARD PROPAGATION
C *** USING SIGMOID TRANSFER FUNCTION
      OJ=1./(1.+EXP(-MATMUL(OI,W)))

C *** USING HYPERBOLIC TANGENT TRANSFER FUNCTION
C      OJ=TANH(MATMUL(OI,W))


C *** STATUS REPORT: CALCULATE ERROR AND CPU TIME AND WRITE
      CALL CPU_TIME(FINISH)
      WRITE(1,*)J, 0.5*SUM((OJ-TJ)**2.), FINISH-START

C *** CALCULATE DELTA
C *** F'(X)=F(X)*(1.-F(X)) FOR F=SIGMOID
      DELTA=(OJ-TJ)*(OJ*(1.-OJ))

C *** F'(X)=1-F(X)^2 FOR F=TANH
C      DELTA=(OJ-TJ)*(1.-OJ**2.)      

C *** UPDATE WEIGHTS (BACKPROPAGATION)
      W = W - ALPHA*MATMUL(TRANSPOSE(OI),DELTA)

      END DO
      
C *** WRITE TRAINED OUTPUT

      WRITE(*,*)'TRAINED OUTPUT'
      WRITE(*,*)OJ(1,1)
      WRITE(*,*)OJ(2,1)
      WRITE(*,*)OJ(3,1)
      WRITE(*,*)OJ(4,1)
      
C *** TEST FOR ANY INPUT NOW

   21 WRITE(*,*)'ENTER THREE ELEMENTS OF A TEST INPUT'
      WRITE(*,*)'BYE TO EXIT'
      READ(*,*)T1,T2,T3
      WSI=T1*W(1,1)+T2*W(2,1)+T3*W(3,1)
C *** USE TRANSFER FUNCTION BEING TESTED
      WRITE(*,*)1./(1.+EXP(-WSI))
C      WRITE(*,*)TANH(WSI)
      GOTO 21

      STOP
      END
      

